UPDATE_AUGMENTER_STATE: &UPDATE_AUGMENTER_STATE true
MIXED_PRECISION_DTYPE: &MIXED_PRECISION_DTYPE float32
NCLASSES: &NCLASSES 10

mode: train
model:
  name: fixmatchmixupcifar10
  helper: KerasDatasetSemiHelper
  helper_kwarg:
    dataset: "cifar10"
    label_ratio: 0.05 # Unlabeled sample ratio.
    unlabel_dataset_ratio: 7 # Unlabeled batch size ratio.
    mixed_precision_dtype: *MIXED_PRECISION_DTYPE
    augment_kwargs:
      name: ctaugment
      kwarg:
        num_layers: 3
        confidence_threshold: 0.8
        decay: 0.99
        epsilon: 0.001
        prob_to_apply: null
        num_levels: 10
  network: imageclassifierCNN13
  network_kwarg:
    input_shape:
      - 32
      - 32
      - 3
    nclasses: *NCLASSES
    filters: 32
train:
  graph_optimizer: true
  graph_optimizer_kwarg:
    layout_optimizer: true
    remapping: true
    shape_optimization: true
    loop_optimization: true
    constant_folding: true
    function_optimization: true
    scoped_allocator_optimization: true
  distributionstrategy_kwarg:
    tpu: null
    strategy: Mirrored
  augmenter: true
  batch_size: 64
  pre_ckpt: null
  rand_seed: 10101
  epochs: 100
  train_epoch_step: 1024
  vali_epoch_step: null
  steps_per_run: 30
  log_dir: log
  sub_log_dir: default_cifar10_fixmatchmixup_ctaug_exp
  mixed_precision:
    enable: false
    dtype: *MIXED_PRECISION_DTYPE
  trainloop: FixMatchMixUpSslLoop
  trainloop_kwarg:
    hparams:
      update_augmenter_state: *UPDATE_AUGMENTER_STATE
      nclasses: *NCLASSES
      fixmatchmixup:
        confidence: 0.95 # 伪标签样本损失置信度过滤阈值
        wu: 1.0 # 无标签样本伪标签损失权重
        wmu: 1.0 # 无标签样本mixup后伪标签损失权重
      ema:
        enable: true
        decay: 0.999
  variablecheckpoint_kwarg:
    variable_dict:
      train_model: train_model
      val_model: val_model
      ema_model: loop.ema.model
      optimizer: optimizer
    monitor: val/acc
    mode: max
  # optimizer: Adam
  # optimizer_kwarg:
  #   learning_rate: 0.001
  #   beta_1: 0.9
  #   beta_2: 0.999
  #   amsgrad: false
  optimizer: SGD
  optimizer_kwarg:
    learning_rate: 0.001
    momentum: 0.9
    nesterov: True
  callbacks:
    - name: EarlyStopping
      kwarg:
        monitor: val/acc
        min_delta: 0
        patience: 50
        verbose: 0
        mode: max
        baseline: null
        restore_best_weights: false
    - name: AugmenterStateSync
      kwarg:
        update_augmenter_state: *UPDATE_AUGMENTER_STATE
    - name: ScheduleLR
      kwarg:
        base_lr: 0.01
        use_warmup: true
        warmup_epochs: 20
        decay_rate: 0.9
        decay_epochs: 20
        outside_optimizer: optimizer

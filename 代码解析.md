# 代码阅读记录

## 1. 数据准备

### 1.1 准备VOC数据

```sh
wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar
wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar
wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar
tar xf VOCtrainval_11-May-2012.tar
tar xf VOCtrainval_06-Nov-2007.tar
tar xf VOCtest_06-Nov-2007.tar
```

### 1.2 生成label

```sh
wget https://pjreddie.com/media/files/voc_label.py
python3 voc_label.py
cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt
```

这一步生成了labels文件夹，里面每个文件的格式如下

```c++
8 0.587 0.7333333333333333 0.122 0.3413333333333333 // obj1的类别, x, y, w, h 
8 0.418 0.848 0.176 0.288							// obj2的类别, x, y, w, h
8 0.536 0.6573333333333333 0.108 0.27999999999999997// obj3的类别, x, y, w, h
```

其中x,y,w,h，是被图像的size缩放后的值

### 1.3 label打包，准备训练数据

```python
# make_voc_list.py
lines = np.array([
    np.array([
        image_path_list[i],											#图像路径
        np.loadtxt(ann_list[i], dtype=float, ndmin=2),				#1.2生成的label文件
        np.array(skimage.io.imread(image_path_list[i]).shape[0:2])] #获取图像的size
    ) for i in range(len(ann_list))])
```

如代码所示，将这些信息打包成一个 n * 3的array（n为训练集图像的数量）:

1. 第一个array 存储了图像路径
2. 第二个array 存储了1.2的label文件
3. 第三个array 存储了训练图像的size

## 2 训练

### 2.1 train anchors

#### 2.1.1 准备数据

```python
X = np.load(f'data/{train_set}_img_ann.npy', allow_pickle=True)
    in_wh = np.array(in_hw[::-1])	# [::-1]表示按步长-1来遍历array，即倒序将h和w付给in_wh
    low = np.array(low)
    high = np.array(high)
    # NOTE correct boxes
    for i in range(len(X)):
        # X[i, 1], X[i, 2]
        img_wh = X[i, 2][::-1]		# X[i, 2]: 第i个训练图像的尺寸 (X是n * 3的array)

        """ calculate the affine transform factor """
        scale = in_wh / img_wh  	# NOTE affine tranform sacle is [w,h]
        scale[:] = np.min(scale)
        translation = ((in_wh - img_wh * scale) / 2).astype(int)		# NOTE translation is [w offset,h offset]

        """ calculate the box transform matrix, in_wh是model的输入，是一个设定好的size """	
        # 将gt中object的 x和y (X[i,1]中的array为1.2的label，[:, 1:3]表示对该array中的col_1和col_2操作，即x和y), 根据图像的大小进行scale和平移 
        X[i, 1][:, 1:3] = (X[i, 1][:, 1:3] * img_wh * scale + translation) / in_wh	
        # 将gt中object的 w和h (X[i,1]中的array为1.2的label，[:, 3:5]表示对该array中的col_3和col_4操作，即w和h), 根据图像的大小进行scale
        X[i, 1][:, 3:5] = (X[i, 1][:, 3:5] * img_wh * scale) / in_wh			   

    x = np.vstack(X[:, 1])			# 用vstack把labels拼成一个array
    x = x[:, 3:]				   # 取col_3和col_4，即w和h，构成一个array   	
    layers = len(out_hw) // 2
    """ 初始化centroids，6 * 2的array """ # anchor_num是3，这变成了6，可能是两个scale的feature map的anchor
    if is_random == 'True':
        initial_centroids = np.hstack
        ((np.random.uniform(low[0], high[0], (layers * anchor_num, 1)),
          np.random.uniform(low[1], high[1], (layers * anchor_num, 1))))
    else:
        initial_centroids = np.vstack((np.linspace(0.05, 0.3, num=layers * anchor_num), np.linspace(0.05, 0.5, num=layers * anchor_num)))
        initial_centroids = initial_centroids.T
    centroids, idx = runkMeans(x, initial_centroids, 10, is_plot)
```

#### 2.1.2 runkMeans

```python
    # build tensorflow graph
    """
  	 将X（训练样本）和c（聚类）构造成同样的shape(train_num, anchor_num, 2)
	 使用numpy.newaxis和numpy.tile新增维度并复制，如X原始的shape为(train_num, 2)，新增一个维度并复制anchor_num次，变成(train_num, anchor_num, 2)
  	"""
    new_x, new_c = tile_x(X, k), tile_c(initial_centroids, m)
    assert new_x.shape == new_c.shape
    in_x, in_c, idx = build_kmeans_graph(new_x, new_c)

    """ run kmeans """
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)

    for i in range(max_iters):
        idx_ = sess.run(idx, feed_dict={in_x: new_x, in_c: new_c})
        new_centrois = computeCentroids(X, idx_, k)
        centroid_history.append(new_centrois.copy())
        new_c = tile_c(new_centrois, m)
```

kMeans生成的anchors进行排序，大的anchors赋值给layer0。

### 2.2 train yolo models

#### 2.2.1 Initialize Data

使用tensorflow.data.Dataset来加载训练数据

```python
def _create_dataset(self, image_ann_list: np.ndarray, batch_size: int, rand_seed: int, is_training: bool, is_resize: bool):
        print(INFO, 'data augment is ', str(is_training))

        def _dataset_parser(img_path: str, true_box: np.ndarray):
            img = self._read_img(img_path.numpy().decode())
            img, true_box = self._process_img(img, true_box, is_training, is_resize)
            labels = self.box_to_label(true_box)
            return (img.astype('float32'), *labels)

        @tf.function
        def _parser_wrapper(img_path: str, true_box: np.ndarray):
            img, *labels = py_function(_dataset_parser, [img_path, true_box], [tf.float32] * (len(self.anchors) + 1))
            # NOTE use wrapper function and dynamic list construct (x,(y_1,y_2,...))
            return img, tuple(labels)

        def gen():
            while True:
                for img_path, true_box, _ in image_ann_list:
                    # NOTE use copy avoid change the annotaion value !
                    yield img_path, np.copy(true_box)

         """
         使用from_generator将img_path和true_box从image_ann_list读取进来
         shuffle : 打乱数据
         map : 调用func，将数据重新映射(代码中将string的img_path转化为图像(Input)；将box转化为label(Output, 7*10*3*(5+20)和14*20*3*(5 + 20)的			feature map))
         batch : 设置batch_size
         tf.data.experimental.AUTOTUNE : CPU能使用的最大并行线程数
         """
        dataset = (tf.data.Dataset.from_generator(gen, (tf.framework_ops.dtypes.string, tf.float32), ([], [None, 5])).
                   shuffle(batch_size * 500 if is_training == True else batch_size * 50, rand_seed).repeat().
                   map(_parser_wrapper, tf.data.experimental.AUTOTUNE).
                   batch(batch_size, True).prefetch(tf.data.experimental.AUTOTUNE))
```

比较关键的一块是生成label，yolo最终的输出是一个feature map，该代码中为7 * 10 * 3 * (5 + 20) 和 14 * 20 * 3 * (5 + 20) 两个layer的feature map。之前生成的ground truth是( class_id, x, y, w, h )，要将其转化为feature map的形式（对于每个train_img都要生成featrue map）。代码如下

```python
def box_to_label(self, true_box: np.ndarray) -> tuple:
    """
    convert the annotaion to yolo v3 label~

        Parameters
        ----------
        true_box : np.ndarray
            annotation shape :[n,5] value :[n*[p,x,y,w,h]]

        Returns
        -------
        tuple
            labels list value :[output_number*[out_h,out_w,anchor_num,class+5]]
            """
    labels = [np.zeros((self.out_hw[i][0], self.out_hw[i][1], len(self.anchors[i]),
                        5 + self.class_num), dtype='float32') for i in range(self.output_number)]
    for box in true_box:
        # NOTE box [x y w h] are relative to the size of the entire image [0~1]
        l, n = self._get_anchor_index(box[3:5])  # [layer index, anchor index]
        idx, idy = self._xy_grid_index(box[1:3], l)  # [x index , y index]
        labels[l][idy, idx, n, 0:4] = np.clip(box[1:5], 1e-8, 1.)
        labels[l][idy, idx, n, 4] = 1.
        labels[l][idy, idx, n, 5 + int(box[0])] = 1.

        return labels
```





